{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRkfvRrDWCMsKBwoGAPQFK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luke2134/Assignment-2-K-Means-DBSCAN-Clustering/blob/main/K-Means%20%26%20DBSCAN%20Clustering%20on%20the%20Olivetti%20Faces%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 2: K-Means & DBSCAN Clustering**"
      ],
      "metadata": {
        "id": "3zynANhU_xJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Retrieve and Load the Olivetti Faces Dataset**"
      ],
      "metadata": {
        "id": "LoPiqszZ_TMT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg7TCOne_O-R",
        "outputId": "42ee0254-1ba5-4b49-ed37-6b8210d476bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /root/scikit_learn_data\n",
            "Data shape: (400, 4096)\n",
            "Number of unique individuals: 40\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "# Load the Olivetti faces dataset\n",
        "data = fetch_olivetti_faces(shuffle=True, random_state=42)\n",
        "X = data.data  # Feature matrix (images as flattened arrays)\n",
        "y = data.target  # Labels (person ID)\n",
        "\n",
        "print(\"Data shape:\", X.shape)\n",
        "print(\"Number of unique individuals:\", len(set(y)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Split the Dataset into Training, Validation, and Test Sets**"
      ],
      "metadata": {
        "id": "LYNLXis6_Yoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into 60% training, 20% validation, and 20% testing\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape)\n",
        "print(\"Test set shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkEJ_4zi_msq",
        "outputId": "0037de22-18b6-46bf-861c-048b0d1527e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (240, 4096)\n",
            "Validation set shape: (80, 4096)\n",
            "Test set shape: (80, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Train a Classifier Using k-Fold Cross-Validation**"
      ],
      "metadata": {
        "id": "1h287U_k_YmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize an SVM classifier\n",
        "svm_clf = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Perform 5-fold cross-validation on the training set\n",
        "cv_scores = cross_val_score(svm_clf, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
        "print(\"Mean CV accuracy:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Uc5X7Do_ncw",
        "outputId": "bbf79399-e1d3-43ea-b7c2-0e235a6e035d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation accuracy scores: [0.875      0.875      0.97916667 0.9375     0.95833333]\n",
            "Mean CV accuracy: 0.925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Use K-Means for Dimensionality Reduction**"
      ],
      "metadata": {
        "id": "zxLWkKtl_Yjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Evaluate silhouette score for different numbers of clusters\n",
        "silhouette_scores = []\n",
        "for k in range(2, 21):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_train)\n",
        "    score = silhouette_score(X_train, kmeans.labels_)\n",
        "    silhouette_scores.append(score)\n",
        "    print(f\"Number of clusters: {k}, Silhouette score: {score}\")\n",
        "\n",
        "# Find the number of clusters with the highest silhouette score\n",
        "optimal_k = silhouette_scores.index(max(silhouette_scores)) + 2\n",
        "print(\"Optimal number of clusters:\", optimal_k)\n",
        "\n",
        "# Perform K-Means clustering with the optimal number of clusters\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "X_train_reduced = kmeans.fit_transform(X_train)\n",
        "X_val_reduced = kmeans.transform(X_val)\n",
        "X_test_reduced = kmeans.transform(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGeYwNS7_n6C",
        "outputId": "a9c77136-7581-4bb8-d199-463e887ef6e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of clusters: 2, Silhouette score: 0.14313338696956635\n",
            "Number of clusters: 3, Silhouette score: 0.12287583202123642\n",
            "Number of clusters: 4, Silhouette score: 0.10660756379365921\n",
            "Number of clusters: 5, Silhouette score: 0.10200099647045135\n",
            "Number of clusters: 6, Silhouette score: 0.09189243614673615\n",
            "Number of clusters: 7, Silhouette score: 0.08148550242185593\n",
            "Number of clusters: 8, Silhouette score: 0.08725398033857346\n",
            "Number of clusters: 9, Silhouette score: 0.09036575257778168\n",
            "Number of clusters: 10, Silhouette score: 0.09058468788862228\n",
            "Number of clusters: 11, Silhouette score: 0.08513794094324112\n",
            "Number of clusters: 12, Silhouette score: 0.08914510160684586\n",
            "Number of clusters: 13, Silhouette score: 0.09072955697774887\n",
            "Number of clusters: 14, Silhouette score: 0.09484771639108658\n",
            "Number of clusters: 15, Silhouette score: 0.08929181098937988\n",
            "Number of clusters: 16, Silhouette score: 0.08971060067415237\n",
            "Number of clusters: 17, Silhouette score: 0.09126953780651093\n",
            "Number of clusters: 18, Silhouette score: 0.09589715301990509\n",
            "Number of clusters: 19, Silhouette score: 0.09475064277648926\n",
            "Number of clusters: 20, Silhouette score: 0.09474339336156845\n",
            "Optimal number of clusters: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Train a Classifier Using the Dimensionality-Reduced Dataset**"
      ],
      "metadata": {
        "id": "UE9VOdGx_Yg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the classifier on the reduced training set\n",
        "svm_clf.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Evaluate the classifier on the reduced validation set\n",
        "val_accuracy = svm_clf.score(X_val_reduced, y_val)\n",
        "print(\"Validation accuracy on the reduced dataset:\", val_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXXwihj-_oT2",
        "outputId": "afad598a-a3e9-46eb-e9fa-fe8985fcdcf9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy on the reduced dataset: 0.275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Apply DBSCAN for Clustering**"
      ],
      "metadata": {
        "id": "BQ5DzUdO_YeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Reduce the dimensionality to a reasonable size using PCA for DBSCAN\n",
        "pca = PCA(n_components=50, random_state=42)  # Reduce to 50 dimensions\n",
        "X_pca = pca.fit_transform(X_train)\n",
        "\n",
        "# Apply DBSCAN with tuned parameters\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5, metric='euclidean', n_jobs=-1)\n",
        "dbscan.fit(X_pca)\n",
        "\n",
        "# Get the cluster labels and number of clusters\n",
        "labels = dbscan.labels_\n",
        "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)  # Exclude noise points\n",
        "n_noise = list(labels).count(-1)\n",
        "\n",
        "print(f\"Number of clusters found by DBSCAN: {n_clusters}\")\n",
        "print(f\"Number of noise points found by DBSCAN: {n_noise}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0AZk-WT_ox4",
        "outputId": "314b68dd-664c-4739-da21-da5ae8d1300d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of clusters found by DBSCAN: 0\n",
            "Number of noise points found by DBSCAN: 240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1KOXMVssBJb9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGypxVe7KpOf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}